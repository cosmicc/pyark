#!/usr/bin/env python3.7

import argparse
import json
import os
import sys
from time import time

import asyncio
from loguru import logger as log
from modules.logwatch import LogWatcher
from modules.processlock import PLock
from modules.redis import redis
from pathlib import Path
from queue import Queue
from modules.configreader import pylogpath, jsonpath, gamelogfile, chatlogfile

log.remove()

HEADER = 5
HEADERSIZE = HEADER * 4 + 4
allinstances = []
pyark_logfile = {}
pyark_debugfile = {}
pyark_gamelogfile = {}
pyark_chatlogfile = {}
clients = {}
globalexitwatch = False

logserver_logfile = Path('/home/ark/shared/logs/pyark/logserver.log')

parser = argparse.ArgumentParser()
parser.add_argument('-v', '--verbose', action='count', default=0)
args = parser.parse_args()

if args.verbose == 0:
    log.add(sink=sys.stderr, level=50, backtrace=False, diagnose=False, colorize=True)
elif args.verbose == 3:
    log.add(sink=sys.stdout, level=5, backtrace=True, diagnose=True, colorize=True)
elif args.verbose == 2:
    log.add(sink=sys.stdout, level=10, backtrace=True, diagnose=True, colorize=True)
elif args.verbose == 1:
    log.add(sink=sys.stdout, level=20, backtrace=True, diagnose=True, colorize=True)
else:
    log.add(sink=sys.stderr, level=50, backtrace=False, diagnose=False, colorize=True)

log.add(sink=str(logserver_logfile), level=20, buffering=1, enqueue=False, backtrace=True, diagnose=True, serialize=False, colorize=False)

processlock = PLock()
processlock.lock()


async def altcallback(filename, lines):
    print(filename)
    for line in lines:
        if not line.strip():
            pass
        elif line.find(':::') == -1:
            for client in client_threads:
                client["queue"].put(line.strip())
        else:
            data = line.split(':::')
            try:
                print(data[0], data[1],
                      zlib.decompress(base64.decodestring(data[2])))
                for client in client_threads:
                    client["queue"].put(zlib.decompress(base64.decodestring(data[2])))
            except Exception as e:
                print(str(e))
                print('caught exception rendering a new game line in %s' % filename)


async def callback(filename, lines):
    for line in lines:
        if not line.strip():
            pass
        elif line.find(':::') == -1:
            await asyncprocesslogline(line)
        else:
            data = line.split(':::')
            try:
                print(data[0], data[1],
                      zlib.decompress(base64.decodestring(data[2])))
                await asyncprocesslogline(zlib.decompress(base64.decodestring(data[2])))
            except Exception as e:
                print(str(e))
                print('caught exception rendering a new log line in %s' % filename)


def removeclient(addr):
    if addr in clients.keys():
        del clients[addr]


async def asynclogclient(reader, writer):
    global clients
    addr = writer.get_extra_info('peername')
    log.debug(f'New client connected: {addr}')
    header = await reader.read(80)
    header = header.decode("utf-8")
    log.trace(f'Client header recieved: {header}')
    log.trace(header.split('!'))
    linerequest = int(header.split('!')[1])
    argsdebug = bool(int(header.split('!')[2]))
    argstrace = bool(int(header.split('!')[3]))
    argsextend = bool(int(header.split('!')[4]))
    argserrors = bool(int(header.split('!')[5]))
    argsstartexit = bool(int(header.split('!')[6]))
    argscommands = bool(int(header.split('!')[7]))
    argserroronly = bool(int(header.split('!')[8]))
    argsjoinleave = bool(int(header.split('!')[9]))
    argsfollow = bool(int(header.split('!')[10]))
    argsserver = header.split('!')[11].strip()
    argslogtype = header.split('!')[12].strip()

    thisqueue = Queue()

    clients.update({addr: {'address': addr, 'logtype': argslogtype, 'queue': thisqueue, 'writer': writer, 'debug': argsdebug, 'trace': argstrace, 'extend': argsextend, 'errors': argserrors, 'startexit': argsstartexit, 'commands': argscommands, 'errorsonly': argserroronly, 'joinleave': argsjoinleave, 'server': argsserver}})

    log.debug(f'Client [{addr}] requested {linerequest} lines')
    if argslogtype == 'game':
        getlines = 50
        startlines = getlines - int(linerequest)
        loglines = await redis.zrange('glhistory', startlines, getlines)
        log.debug(f'gamelines history retrived: {len(loglines)}')
        for line in loglines:
            thisqueue.put(line.decode().strip())

    elif argslogtype == 'chat':
        getlines = 20
        startlines = getlines - int(linerequest)
        loglines = await redis.zrange('clhistory', startlines, getlines)
        log.debug(f'chatlines history retrived: {len(loglines)}')
        for line in loglines:
            thisqueue.put(line.decode().strip())

    elif argslogtype == 'pyark':
        try:
            if argsdebug or argstrace:
                await redis.zunionstore('mergelog', ['pyarklog', 'pyarkdebuglog'])
                getlog = 'mergelog'
                getlines = 100
            else:
                getlog = 'pyarklog'
                getlines = 50
            startlines = getlines - int(linerequest)
            loglines = await redis.zrange(getlog, startlines, getlines)
            log.debug(f'Loglines history retrived: {len(loglines)}')
            for line in loglines:
                thisqueue.put(line.decode().strip())
            if argsdebug or argstrace:
                await redis.delete('mergelog')
        except:
            log.exception('SHIT')

    if not argsfollow:
        while not thisqueue.empty():
            await asyncsendmsg(writer, addr, thisqueue.get())
        await asyncio.sleep(.01)
        await asyncsendmsg(writer, addr, '##')
        log.info(f'Non follow connection ended. Removing: [{addr}]')
        removeclient(addr)
    else:
        asyncio.create_task(asyncmainclientloop(writer, addr, thisqueue))


async def asyncmainclientloop(writer, addr, thisqueue):
    log.debug(f'Main client loop started for [{addr}]')
    exitwatch = False
    heartbeattime = time()
    while not exitwatch:
        if addr not in clients:
            exitwatch = True
            log.debug(f'Ending client loop for [{addr}]')
        else:
            if time() - heartbeattime >= 15:
                await asyncsendmsg(writer, addr, '!')
                heartbeattime = time()
            elif not thisqueue.empty():
                await asyncsendmsg(writer, addr, thisqueue.get())
            else:
                await asyncio.sleep(.05)


async def asyncsendmsg(writer, addr, logline):
    global clients
    try:
        if logline == '!':
            nlogline = logline.encode("utf-32")
            msg = f'{len(nlogline):<{HEADER}}'.encode("utf-32") + nlogline
            writer.write(msg)
            await writer.drain()
        else:
            nlogline = logline.strip().encode("utf-32")
            msg = f'{len(nlogline):<{HEADER}}'.encode("utf-32") + nlogline
            writer.write(msg)
            await writer.drain()
    except ConnectionResetError:
        log.info(f'Dropped connection detected. Removing: {addr}')
        removeclient(addr)
    except BrokenPipeError:
        log.info(f'Dead connection detected. Removing: {addr}')
        removeclient(addr)


@log.catch
async def asyncputqueue(data, client, single):
    if not single or single == client['address']:
        if client['server'] == 'ALL' or client['server'] == data["record"]["extra"]['hostname']:
            log.trace(f'Adding to {client["address"]} queue {data["text"].strip()}')
            if client['debug'] or client['trace'] or client['extend']:
                msgapp = f' \u001b[38;5;109m{data["record"]["module"]}:{data["record"]["function"]}:{data["record"]["line"]}'
                client["queue"].put(data["text"].strip() + msgapp)
            else:
                client["queue"].put(data["text"].strip())


@log.catch
async def asyncprocesslogline(line, single=False):
    try:
        line = line.strip('\x00')
        data = json.loads(line.strip(), strict=False)
        log.debug(f'Got from log: {data["record"]["time"]["timestamp"]}')
        if data["record"]["level"]["name"] == 'TRACE' or data["record"]["level"]["name"] == 'DEBUG' or data["record"]["level"]["name"] == 'ERROR' or data["record"]["level"]["name"] == 'CRITICAL' or data["record"]["level"]["name"] == 'EXIT' or data["record"]["level"]["name"] == 'START' or data["record"]["level"]["name"] == 'GIT':
            debugcount = int(await redis.zcard('pyarkdebuglog'))
            if debugcount == 50:
                await redis.zremrangebyrank('pyarkdebuglog', 0, 0)
            await redis.zadd('pyarkdebuglog', data["record"]["time"]["timestamp"], data["text"])
        else:
            count = int(await redis.zcard('pyarklog'))
            if count == 50:
                await redis.zremrangebyrank('pyarklog', 0, 0)
            await redis.zadd('pyarklog', data["record"]["time"]["timestamp"], data["text"])
        for client in clients.keys():
            if data["record"]["level"]["name"] == "ERROR" or data["record"]["level"]["name"] == "CRITICAL":
                if clients[client]['errors'] or clients[client]['errorsonly']:
                    await asyncputqueue(data, clients[client], single)
            elif data["record"]["level"]["name"] == 'WARNING':
                await asyncputqueue(data, clients[client], single)
            elif data["record"]["level"]["name"] == 'TRACE':
                if clients[client]['trace'] and not clients[client]['errorsonly']:
                    await asyncputqueue(data, clients[client], single)
            elif data["record"]["level"]["name"] == 'DEBUG':
                if clients[client]['debug'] and not clients[client]['errorsonly']:
                    await asyncputqueue(data, clients[client], single)
            elif data["record"]["level"]["name"] == "START" or data["record"]["level"]["name"] == "EXIT" or data["record"]["level"]["name"] == "ERROR" or data["record"]["level"]["name"] == "CRITICAL" or data["record"]["level"]["name"] == "GIT":
                if clients[client]['startexit'] and not clients[client]['errorsonly']:
                    await asyncputqueue(data, clients[client], single)
            elif data["record"]["level"]["name"] == "CMD":
                if clients[client]['commands'] and not clients[client]['errorsonly']:
                    await asyncputqueue(data, clients[client], single)
            elif data["record"]["level"]["name"] == "JOIN" or data["record"]["level"]["name"] == "LEAVE":
                if clients[client]['joinleave'] and not clients[client]['errorsonly']:
                    await asyncputqueue(data, clients[client], single)
            elif not clients[client]['errorsonly']:
                await asyncputqueue(data, clients[client], single)

    except json.decoder.JSONDecodeError:
        log.error(f'DECODE ERROR: {repr(line)}')


@log.catch
async def loglistener(lw):
    while not globalexitwatch:
        lw.loop(nonblocking=True)
        await asyncio.sleep(.1)


@log.catch
async def altloglistener(lg):
    while not globalexitwatch:
        lg.loop(nonblocking=True)
        await asyncio.sleep(.1)


@log.catch
async def asyncmain():
    global client_threads
    await redis.delete('pyarklog', 'pyarkdebuglog', 'glhistory', 'clhistory')
    allservers = ()
    for aserver in await redis.smembers('cliservers'):
        allservers = allservers + (aserver.decode(),)
    for server in allservers:
        pyark_logfile.update({server: Path(f'/home/ark/shared/logs/pyark/json/{server}_log.json')})
        pyark_debugfile.update({server: Path(f'/home/ark/shared/logs/pyark/json/{server}_debug.json')})
    lw = LogWatcher(str(jsonpath), callback, extensions=['json'], tail_lines=50)
    lg = LogWatcher(str(pylogpath), altcallback, matching_file_names=['game.log', 'clusterchat.log'], extensions=['log'], tail_lines=50)
    asyncio.create_task(altloglistener(lg))
    asyncio.create_task(loglistener(lw))
    server = await asyncio.start_server(asynclogclient, '172.31.250.115', 11024)
    async with server:
        await server.serve_forever()


def endtail(f, lines=1, _buffer=12288):
    """Tail a file and get X lines from the end"""
    lines_found = []
    block_counter = -1
    while len(lines_found) < lines:
        try:
            f.seek(block_counter * _buffer, os.SEEK_END)
        except IOError:  # either file is too small, or too many lines requested
            f.seek(0)
            lines_found = f.readlines()
            break

        lines_found = f.readlines()
        block_counter -= 1

    return lines_found[-lines:]


if __name__ == '__main__':
    os.nice(19)
    asyncio.run(asyncmain())
