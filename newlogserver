#!/usr/bin/env python3.7

import argparse
import json
import os
import socket
import sys
import threading
from datetime import datetime
from queue import Queue
from time import sleep
from pathlib import Path

from loguru import logger as log

from modules.processlock import PLock
from modules.logwatch import LogWatcher
from modules.configreader import redis_host, redis_port
from redis import Redis

log.remove()

HEADER = 5
HEADERSIZE = HEADER * 4 + 4
allinstances = []
pyark_logfile = {}
pyark_debugfile = {}
pyark_gamelogfile = {}
pyark_chatlogfile = {}

redis = Redis(host=redis_host, port=redis_port, db=0)
allservers = ()
for aserver in redis.smembers('cliservers'):
    allservers = allservers + (aserver.decode(),)

logserver_logfile = Path('/home/ark/shared/logs/pyark/logserver.log')
print(allservers)
for server in allservers:
    pyark_logfile.update({server: Path(f'/home/ark/shared/logs/pyark/json/{server}_log.json')})
    pyark_debugfile.update({server: Path(f'/home/ark/shared/logs/pyark/json/{server}_debug.json')})
    pyark_gamelogfile.update({server: Path(f'/home/ark/shared/logs/pyark/json/{server}_game.json')})
    pyark_chatlogfile.update({server: Path(f'/home/ark/shared/logs/pyark/json/{server}_chat.json')})

log_queue = Queue()

parser = argparse.ArgumentParser()
parser.add_argument('-v', '--verbose', action='count', default=0)
args = parser.parse_args()

if args.verbose == 0:
    log.add(sink=sys.stderr, level=50, backtrace=False, diagnose=False, colorize=True)
elif args.verbose == 3:
    log.add(sink=sys.stdout, level=5, backtrace=True, diagnose=True, colorize=True)
elif args.verbose == 2:
    log.add(sink=sys.stdout, level=10, backtrace=True, diagnose=True, colorize=True)
elif args.verbose == 1:
    log.add(sink=sys.stdout, level=20, backtrace=True, diagnose=True, colorize=True)
else:
    log.add(sink=sys.stderr, level=50, backtrace=False, diagnose=False, colorize=True)

log.add(sink=str(logserver_logfile), level=20, buffering=1, enqueue=False, backtrace=True, diagnose=True, serialize=False, colorize=False)

processlock = PLock()
processlock.lock()


def checkconnections():
    for client in client_threads:
        if not client['thread'].is_alive():
            log.info(f'Lost thread detected. Removing: {client["address"]}')
            client_threads.remove(client)


def callback(filename, lines):
    for line in lines:
        if not line.strip():
            pass
        elif line.find(':::') == -1:
            processlogline(line)
        else:
            data = line.split(':::')
            try:
                print(data[0], data[1],
                      zlib.decompress(base64.decodestring(data[2])))
                processlogline(zlib.decompress(base64.decodestring(data[2])))
            except Exception as e:
                print(str(e))
                print('caught exception rendering a new log line in %s' % filename)


def logwatcher():
    lw = LogWatcher("/home/ark/shared/logs/pyark/json", callback, tail_lines=50)
    lw.loop()


def clientloop(clientsocket, addr):
    log.debug(f'New thread started for client: {addr}')
    for client in client_threads:
        if client['address'] == addr:
            thisqueue = client['queue']
            log.trace(f'found queue: {thisqueue}')
    now = int(datetime.now().timestamp())
    header = clientsocket.recv(80).decode("utf-8")
    log.trace(header.split('!'))
    linerequest = int(header.split('!')[1])
    argsdebug = bool(int(header.split('!')[2]))
    argstrace = bool(int(header.split('!')[3]))
    argsextend = bool(int(header.split('!')[4]))
    argserrors = bool(int(header.split('!')[5]))
    argsstartexit = bool(int(header.split('!')[6]))
    argscommands = bool(int(header.split('!')[7]))
    argserroronly = bool(int(header.split('!')[8]))
    argsjoinleave = bool(int(header.split('!')[9]))
    argsfollow = bool(int(header.split('!')[10]))
    argsserver = header.split('!')[11].strip()
    argsshowonly = header.split('!')[12].strip()

    newdict = {}
    for num, client in enumerate(client_threads):
        if client['address'] == addr:
            newdict = {'address': client['address'], 'thread': client['thread'], 'queue': client['queue'], 'socket': client['socket'], 'debug': argsdebug, 'trace': argstrace, 'extend': argsextend, 'errors': argserrors, 'startexit': argsstartexit, 'commands': argscommands, 'errorsonly': argserroronly, 'joinleave': argsjoinleave, 'server': argsserver, 'showonly': argsshowonly}
            client_threads.pop(num)
            client_threads.append(newdict)
            log.debug(newdict)

    log.debug(f'Requested playback of {linerequest} lines')
    try:
        startlines = 50 - int(linerequest)
        loglines = redis.zrange('pyarklog', startlines, 50)
        log.debug(f'Loglines history retrived: {len(loglines)}')
        for line in loglines:
            thisqueue.put(line.decode().strip())
            # if line[0] == 'TRACE':
            #    if client['trace'] and not client['errorsonly']:
            #        thisqueue.put(line[1].strip())
    except:
        log.exception('SHIT')
    if not argsfollow:
        for num, client in enumerate(client_threads):
            if int(client['address']) == int(addr):
                while not thisqueue.empty():
                    logline = thisqueue.get()
                    log.trace(f'got from queue: {logline}')
                    sendmsg(clientsocket, addr, logline)
                sleep(.01)
                sendmsg(clientsocket, addr, '##')
                log.info(f'Non follow connection ended. Removing: {client["address"]}')
                client_threads.pop(num)
                sleep(1)
    log.trace('main loop started')
    while True:
        exitwatch = True
        for client in client_threads:
            if client['address'] == addr:
                exitwatch = False
        if exitwatch:
            log.debug(f'Ending thread for port {addr}')
            exit(0)
        if int(datetime.now().timestamp()) - now >= 15:
            log.trace(f'Sending heartbeat to {addr}')
            sendmsg(clientsocket, addr, '!')
            now = int(datetime.now().timestamp())

        if not thisqueue.empty():
            logline = thisqueue.get()
            log.trace(f'got from queue: {logline.split("|")[2]}')
            sendmsg(clientsocket, addr, logline)
        else:
            sleep(.01)


def sendmsg(clientsocket, addr, logline):
    global client_threads
    try:
        if logline == '!':
            nlogline = logline.encode("utf-32")
            msg = f'{len(nlogline):<{HEADER}}'.encode("utf-32") + nlogline
            clientsocket.sendall(msg)
        else:
            nlogline = logline.strip().encode("utf-32")
            msg = f'{len(nlogline):<{HEADER}}'.encode("utf-32") + nlogline
            log.debug(f'sending: {len(nlogline)}')
            clientsocket.sendall(msg)
    except ConnectionResetError:
        clist = client_threads.copy()
        for num, client in enumerate(clist):
            if int(client['address']) == int(addr):
                log.info(f'Dropped connection detected. Removing: {client["address"]}')
                client_threads.pop(num)
    except BrokenPipeError:
        clist = client_threads.copy()
        for num, client in enumerate(clist):
            if int(client['address']) == int(addr):
                log.info(f'Dead connection detected. Removing: {client["address"]}')
                client_threads.remove(client)


def endtail(f, lines=1, _buffer=12288):
    """Tail a file and get X lines from the end"""
    lines_found = []
    block_counter = -1
    while len(lines_found) < lines:
        try:
            f.seek(block_counter * _buffer, os.SEEK_END)
        except IOError:  # either file is too small, or too many lines requested
            f.seek(0)
            lines_found = f.readlines()
            break

        lines_found = f.readlines()
        block_counter -= 1

    return lines_found[-lines:]


def waitallclients():
    clist = client_threads.copy()
    for num, client in enumerate(clist):
        sendmsg(client["socket"], client["address"], '#!')
        log.info(f'Ending connection. Removing: {client["address"]}')
        sleep(.1)
        client_threads.remove(client)


@log.catch
def putqueue(data, client, single):
    if not single or single == client['address']:
        if client['server'] == 'ALL' or client['server'] == data["record"]["extra"]['hostname']:
            log.trace(f'Adding to {client["address"]} queue {data["text"].strip()}')
            if client['debug'] or client['trace'] or client['extend']:
                msgapp = f' \u001b[38;5;109m{data["record"]["module"]}:{data["record"]["function"]}:{data["record"]["line"]}'
                client["queue"].put(data["text"].strip() + msgapp)
            else:
                client["queue"].put(data["text"].strip())


@log.catch
def processlogline(line, single=False):
    try:
        line = line.strip('\x00')
        data = json.loads(line.strip(), strict=False)
        # log.debug(f'Got from log: {data["record"]["time"]["timestamp"]}')
        if data["record"]["level"]["name"] == 'TRACE' or data["record"]["level"]["name"] == 'TRACE' or data["record"]["level"]["name"] == 'ERROR' or data["record"]["level"]["name"] == 'CRITICAL':
            debugcount = int(redis.zcard('pyarkdebuglog'))
            if debugcount == 50:
                redis.zremrangebyrank('pyarkdebuglog', 0, 0)
            redis.zadd('pyarkdebuglog', {data["text"]: data["record"]["time"]["timestamp"]}, nx=True)
        else:
            count = int(redis.zcard('pyarklog'))
            if count == 50:
                redis.zremrangebyrank('pyarklog', 0, 0)
            redis.zadd('pyarklog', {data["text"]: data["record"]["time"]["timestamp"]}, nx=True)
        for client in client_threads:
            if client['showonly'] != 'ALL':
                if data["record"]["level"]["name"].lower() == client['showonly'].lower():
                    putqueue(data, client, single)
            else:
                if data["record"]["level"]["name"] == "ERROR" or data["record"]["level"]["name"] == "CRITICAL":
                    if client['errors'] or client['errorsonly']:
                        putqueue(data, client, single)
                elif data["record"]["level"]["name"] == 'WARNING':
                    putqueue(data, client, single)
                elif data["record"]["level"]["name"] == 'TRACE':
                    if client['trace'] and not client['errorsonly']:
                        putqueue(data, client, single)
                elif data["record"]["level"]["name"] == 'DEBUG':
                    if client['debug'] and not client['errorsonly']:
                        putqueue(data, client, single)
                elif data["record"]["level"]["name"] == "START" or data["record"]["level"]["name"] == "EXIT" or data["record"]["level"]["name"] == "ERROR" or data["record"]["level"]["name"] == "CRITICAL" or data["record"]["level"]["name"] == "GIT":
                    if client['startexit'] and not client['errorsonly']:
                        putqueue(data, client, single)
                elif data["record"]["level"]["name"] == "CMD":
                    if client['commands'] and not client['errorsonly']:
                        putqueue(data, client, single)
                elif data["record"]["level"]["name"] == "JOIN" or data["record"]["level"]["name"] == "LEAVE":
                    if client['joinleave'] and not client['errorsonly']:
                        putqueue(data, client, single)
                elif not client['errorsonly']:
                    putqueue(data, client, single)
            sleep(.01)

    except json.decoder.JSONDecodeError:
        log.error(f'DECODE ERROR: {repr(line)}')


@log.catch
def main():
    global client_threads
    os.nice(15)
    redis.delete('pyarklog', 'pyarkdebuglog')
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.bind(('172.31.250.115', 11024))
    log.debug('Starting log tail thread')
    logwatch_thread = threading.Thread(target=logwatcher)
    logwatch_thread.start()
    client_threads = []
    cleanup_thread = threading.Thread(target=checkconnections)
    cleanup_thread.start()
    log.info('Server started, waiting for clients...')
    s.listen(4)
    while True:
        clientsocket, address = s.accept()
        log.info(f"Connection from {address[0]}:{address[1]} has been established")
        nthread = threading.Thread(target=clientloop, args=(clientsocket, address[1]))
        client_threads.append({'address': address[1], 'thread': nthread, 'queue': Queue(), 'socket': clientsocket, 'debug': False, 'trace': False, 'extend': False, 'admin': True, 'startexit': True, 'commands': True, 'votes': True, 'joinleave': True, 'server': 'ALL', 'showonly': 'ALL'})
        log.trace(client_threads)
        nthread.start()

    s.close()


@log.catch
def startconnect():
        # watchlog(False)
    logpath = f'/home/ark/shared/logs/pyark/pyarklog.json'
    with open(logpath) as f:
        lines = endtail(f, lines=1)
        for line in lines:
            processlogline(line)


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        waitallclients()
        sleep(1)
        os._exit(0)
